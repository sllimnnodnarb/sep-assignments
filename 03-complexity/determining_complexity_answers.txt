1. What's the Big-O of the following algorithm?
  def goodbye_world(n)
   puts "Goodbye World! #{n}"
  end

O(1) because the value can never change, it is not complex because there are no iterations even, it literally just prints the value passed in to the function.


2. What's the Big-O of the following algorithm?
  def find_largest(collection)
    largest = collection[0]
    collection.length.times do |i|
       if collection[i] >= largest
         largest = collection[i]
       end
    end
    largest
  end

O(n) seems to be worst case here for the reason that the length of the collection will be the worst case scenario.  It runs in linear time.


3. What's the Big-O of the following algorithm?
  def find_largest(collection)
    largest = collection[0][0]
    collection.length.times do |i|
      subcollection = collection[i]
      subcollection.length.times do |i|
        if subcollection[i] >= largest
          largest = subcollection[i]
        end
      end
    end
    largest
  end

O(n^2) here there is an iteration within an iteration. This will be a slow method based on the fact that n will double with each iteration.  Each subcollection must be iterated over until the highest number is found, which will happen collection.length.times, then subcollection.length.times after that until the largest value is located. Then the comparison happens against the original. Assuming collection.length is a rational number.  The growth should be linear and increasing dependent on size.


4. What's the Big-O of the following algorithm?
  def numbers(n)
    if (n == 0)
     return 0
    elsif (n == 1)
     return 1
    else
     return numbers(n-1) + numbers(n-2)
    end
  end

O(2^n). There are two recursive instances here so when numbers(n-1) + numbers(n-2) it results in "2" raised to the nth power.


5. What's the Big-O of the following algorithm?
  def iterative(n)
   num1 = 0
   num2 = 1
   i = 0
   while i < n-1
     tmp = num1 + num2
     num1 = num2
     num2 = tmp
     i+=1
   end
   num2
  end

O(n) for the fact that the value of n will dictate the runtime.  It should be linear.


6. What's the Big-O of the following algorithm?
  def sort(collection, from=0, to=nil)
    if to == nil
      # Sort the whole collection, by default
      to = collection.count - 1
    end

    if from >= to
      # Done sorting
      return
    end

    # Take a pivot value, at the far left
    pivot = collection[from]

    # Min and Max pointers
    min = from
    max = to

    # Current free slot
    free = min

    while min < max
      if free == min # Evaluate collection[max]
        if collection[max] <= pivot # Smaller than pivot, must move
          collection[free] = collection[max]
          min += 1
          free = max
        else
          max -= 1
        end
      elsif free == max # Evaluate collection[min]
        if collection[min] >= pivot # Bigger than pivot, must move
          collection[free] = collection[min]
          max -= 1
          free = min
        else
          min += 1
        end
      else
        raise "Inconsistent state"
      end
    end

    collection[free] = pivot

    quick_sort collection, from, free - 1
    quick_sort collection, free + 1, to

    collection
  end

O(nâ€‹^2), as the recursive calls increase, they grow exponentially deeper in terms of layers.  This true as long as there is something to sort, that is, if the collection is greater than 2. Quicksort cannot pivot unless there are enough indices to establish a pivot; 3. The assumption in any sorting method is that the collection needs to be sorted.  If the collection is already sorted this would result in BigO = O(n^2) because the pivot point would only move one index.
